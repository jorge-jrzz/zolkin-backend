{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "%pip install -qU langchain-redis langchain-openai redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Redis at: redis://localhost:6379/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use the environment variable if set, otherwise default to localhost\n",
    "REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379/')\n",
    "print(f\"Connecting to Redis at: {REDIS_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat History:\n",
      "HumanMessage: Hello, AI assistant!\n",
      "AIMessage: Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_redis import RedisChatMessageHistory\n",
    "\n",
    "# Initialize RedisChatMessageHistory\n",
    "history = RedisChatMessageHistory(session_id=\"user_123\", redis_url=REDIS_URL)\n",
    "\n",
    "# Add messages to the history\n",
    "history.add_user_message(\"Hello, AI assistant!\")\n",
    "history.add_ai_message(\"Hello! How can I assist you today?\")\n",
    "\n",
    "# Retrieve messages\n",
    "print(\"Chat History:\")\n",
    "for message in history.messages:\n",
    "    print(f\"{type(message).__name__}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response 1: Hello Alice! How can I assist you today?\n",
      "AI Response 2: Your name is Alice.\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Create the conversational chain\n",
    "chain = prompt | llm\n",
    "\n",
    "\n",
    "# Function to get or create a RedisChatMessageHistory instance\n",
    "def get_redis_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    return RedisChatMessageHistory(session_id, redis_url=REDIS_URL)\n",
    "\n",
    "\n",
    "# Create a runnable with message history\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain, get_redis_history, input_messages_key=\"input\", history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# Use the chain in a conversation\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"input\": \"Hi, my name is Alice.\"},\n",
    "    config={\"configurable\": {\"session_id\": \"alice_123\"}},\n",
    ")\n",
    "print(\"AI Response 1:\", response1.content)\n",
    "\n",
    "response2 = chain_with_history.invoke(\n",
    "    {\"input\": \"What's my name?\"}, config={\"configurable\": {\"session_id\": \"alice_123\"}}\n",
    ")\n",
    "print(\"AI Response 2:\", response2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver  # an in-memory checkpointer\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "system_message = \"You are a helpful assistant.\"\n",
    "# This could also be a SystemMessage object\n",
    "# system_message = SystemMessage(content=\"You are a helpful assistant. Respond only in Spanish.\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "langgraph_agent_executor = create_react_agent(\n",
    "    llm, tools, state_modifier=system_message, checkpointer=memory\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
    "print(\n",
    "    langgraph_agent_executor.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                (\"user\", \"Hi, I'm polly! What's the output of magic_function of 3?\")\n",
    "            ]\n",
    "        },\n",
    "        config,\n",
    "    )[\"messages\"][-1].content\n",
    ")\n",
    "print(\"---\")\n",
    "print(\n",
    "    langgraph_agent_executor.invoke(\n",
    "        {\"messages\": [(\"user\", \"Remember my name?\")]}, config\n",
    "    )[\"messages\"][-1].content\n",
    ")\n",
    "print(\"---\")\n",
    "print(\n",
    "    langgraph_agent_executor.invoke(\n",
    "        {\"messages\": [(\"user\", \"what was that output again?\")]}, config\n",
    "    )[\"messages\"][-1].content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation of a langgraph checkpoint saver using Redis.\"\"\"\n",
    "from contextlib import asynccontextmanager, contextmanager\n",
    "from typing import (\n",
    "    Any,\n",
    "    AsyncGenerator,\n",
    "    AsyncIterator,\n",
    "    Iterator,\n",
    "    List,\n",
    "    Optional,\n",
    "    Tuple,\n",
    ")\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.base import (\n",
    "    BaseCheckpointSaver,\n",
    "    ChannelVersions,\n",
    "    Checkpoint,\n",
    "    CheckpointMetadata,\n",
    "    CheckpointTuple,\n",
    "    PendingWrite,\n",
    "    get_checkpoint_id,\n",
    ")\n",
    "from langgraph.checkpoint.serde.base import SerializerProtocol\n",
    "from redis import Redis\n",
    "from redis.asyncio import Redis as AsyncRedis\n",
    "\n",
    "REDIS_KEY_SEPARATOR = \":\"\n",
    "\n",
    "\n",
    "# Utilities shared by both RedisSaver and AsyncRedisSaver\n",
    "\n",
    "\n",
    "def _make_redis_checkpoint_key(\n",
    "    thread_id: str, checkpoint_ns: str, checkpoint_id: str\n",
    ") -> str:\n",
    "    return REDIS_KEY_SEPARATOR.join(\n",
    "        [\"checkpoint\", thread_id, checkpoint_ns, checkpoint_id]\n",
    "    )\n",
    "\n",
    "\n",
    "def _make_redis_checkpoint_writes_key(\n",
    "    thread_id: str,\n",
    "    checkpoint_ns: str,\n",
    "    checkpoint_id: str,\n",
    "    task_id: str,\n",
    "    idx: Optional[int],\n",
    ") -> str:\n",
    "    if idx is None:\n",
    "        return REDIS_KEY_SEPARATOR.join(\n",
    "            [\"writes\", thread_id, checkpoint_ns, checkpoint_id, task_id]\n",
    "        )\n",
    "\n",
    "    return REDIS_KEY_SEPARATOR.join(\n",
    "        [\"writes\", thread_id, checkpoint_ns, checkpoint_id, task_id, str(idx)]\n",
    "    )\n",
    "\n",
    "\n",
    "def _parse_redis_checkpoint_key(redis_key: str) -> dict:\n",
    "    namespace, thread_id, checkpoint_ns, checkpoint_id = redis_key.split(\n",
    "        REDIS_KEY_SEPARATOR\n",
    "    )\n",
    "    if namespace != \"checkpoint\":\n",
    "        raise ValueError(\"Expected checkpoint key to start with 'checkpoint'\")\n",
    "\n",
    "    return {\n",
    "        \"thread_id\": thread_id,\n",
    "        \"checkpoint_ns\": checkpoint_ns,\n",
    "        \"checkpoint_id\": checkpoint_id,\n",
    "    }\n",
    "\n",
    "\n",
    "def _parse_redis_checkpoint_writes_key(redis_key: str) -> dict:\n",
    "    namespace, thread_id, checkpoint_ns, checkpoint_id, task_id, idx = redis_key.split(\n",
    "        REDIS_KEY_SEPARATOR\n",
    "    )\n",
    "    if namespace != \"writes\":\n",
    "        raise ValueError(\"Expected checkpoint key to start with 'checkpoint'\")\n",
    "\n",
    "    return {\n",
    "        \"thread_id\": thread_id,\n",
    "        \"checkpoint_ns\": checkpoint_ns,\n",
    "        \"checkpoint_id\": checkpoint_id,\n",
    "        \"task_id\": task_id,\n",
    "        \"idx\": idx,\n",
    "    }\n",
    "\n",
    "\n",
    "def _filter_keys(\n",
    "    keys: List[str], before: Optional[RunnableConfig], limit: Optional[int]\n",
    ") -> list:\n",
    "    \"\"\"Filter and sort Redis keys based on optional criteria.\"\"\"\n",
    "    if before:\n",
    "        keys = [\n",
    "            k\n",
    "            for k in keys\n",
    "            if _parse_redis_checkpoint_key(k.decode())[\"checkpoint_id\"]\n",
    "            < before[\"configurable\"][\"checkpoint_id\"]\n",
    "        ]\n",
    "\n",
    "    keys = sorted(\n",
    "        keys,\n",
    "        key=lambda k: _parse_redis_checkpoint_key(k.decode())[\"checkpoint_id\"],\n",
    "        reverse=True,\n",
    "    )\n",
    "    if limit:\n",
    "        keys = keys[:limit]\n",
    "    return keys\n",
    "\n",
    "\n",
    "def _dump_writes(serde: SerializerProtocol, writes: tuple[str, Any]) -> list[dict]:\n",
    "    \"\"\"Serialize pending writes.\"\"\"\n",
    "    serialized_writes = []\n",
    "    for channel, value in writes:\n",
    "        type_, serialized_value = serde.dumps_typed(value)\n",
    "        serialized_writes.append(\n",
    "            {\"channel\": channel, \"type\": type_, \"value\": serialized_value}\n",
    "        )\n",
    "    return serialized_writes\n",
    "\n",
    "\n",
    "def _load_writes(\n",
    "    serde: SerializerProtocol, task_id_to_data: dict[tuple[str, str], dict]\n",
    ") -> list[PendingWrite]:\n",
    "    \"\"\"Deserialize pending writes.\"\"\"\n",
    "    writes = [\n",
    "        (\n",
    "            task_id,\n",
    "            data[b\"channel\"].decode(),\n",
    "            serde.loads_typed((data[b\"type\"].decode(), data[b\"value\"])),\n",
    "        )\n",
    "        for (task_id, _), data in task_id_to_data.items()\n",
    "    ]\n",
    "    return writes\n",
    "\n",
    "\n",
    "def _parse_redis_checkpoint_data(\n",
    "    serde: SerializerProtocol,\n",
    "    key: str,\n",
    "    data: dict,\n",
    "    pending_writes: Optional[List[PendingWrite]] = None,\n",
    ") -> Optional[CheckpointTuple]:\n",
    "    \"\"\"Parse checkpoint data retrieved from Redis.\"\"\"\n",
    "    if not data:\n",
    "        return None\n",
    "\n",
    "    parsed_key = _parse_redis_checkpoint_key(key)\n",
    "    thread_id = parsed_key[\"thread_id\"]\n",
    "    checkpoint_ns = parsed_key[\"checkpoint_ns\"]\n",
    "    checkpoint_id = parsed_key[\"checkpoint_id\"]\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,\n",
    "            \"checkpoint_ns\": checkpoint_ns,\n",
    "            \"checkpoint_id\": checkpoint_id,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    checkpoint = serde.loads_typed((data[b\"type\"].decode(), data[b\"checkpoint\"]))\n",
    "    metadata = serde.loads(data[b\"metadata\"].decode())\n",
    "    parent_checkpoint_id = data.get(b\"parent_checkpoint_id\", b\"\").decode()\n",
    "    parent_config = (\n",
    "        {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"checkpoint_ns\": checkpoint_ns,\n",
    "                \"checkpoint_id\": parent_checkpoint_id,\n",
    "            }\n",
    "        }\n",
    "        if parent_checkpoint_id\n",
    "        else None\n",
    "    )\n",
    "    return CheckpointTuple(\n",
    "        config=config,\n",
    "        checkpoint=checkpoint,\n",
    "        metadata=metadata,\n",
    "        parent_config=parent_config,\n",
    "        pending_writes=pending_writes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedisSaver(BaseCheckpointSaver):\n",
    "    \"\"\"Redis-based checkpoint saver implementation.\"\"\"\n",
    "\n",
    "    conn: Redis\n",
    "\n",
    "    def __init__(self, conn: Redis):\n",
    "        super().__init__()\n",
    "        self.conn = conn\n",
    "\n",
    "    @classmethod\n",
    "    @contextmanager\n",
    "    def from_conn_info(cls, *, host: str, port: int, db: int) -> Iterator[\"RedisSaver\"]:\n",
    "        conn = None\n",
    "        try:\n",
    "            conn = Redis(host=host, port=port, db=db)\n",
    "            yield RedisSaver(conn)\n",
    "        finally:\n",
    "            if conn:\n",
    "                conn.close()\n",
    "\n",
    "    def put(\n",
    "        self,\n",
    "        config: RunnableConfig,\n",
    "        checkpoint: Checkpoint,\n",
    "        metadata: CheckpointMetadata,\n",
    "        new_versions: ChannelVersions,\n",
    "    ) -> RunnableConfig:\n",
    "        \"\"\"Save a checkpoint to Redis.\n",
    "\n",
    "        Args:\n",
    "            config (RunnableConfig): The config to associate with the checkpoint.\n",
    "            checkpoint (Checkpoint): The checkpoint to save.\n",
    "            metadata (CheckpointMetadata): Additional metadata to save with the checkpoint.\n",
    "            new_versions (ChannelVersions): New channel versions as of this write.\n",
    "\n",
    "        Returns:\n",
    "            RunnableConfig: Updated configuration after storing the checkpoint.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        checkpoint_ns = config[\"configurable\"][\"checkpoint_ns\"]\n",
    "        checkpoint_id = checkpoint[\"id\"]\n",
    "        parent_checkpoint_id = config[\"configurable\"].get(\"checkpoint_id\")\n",
    "        key = _make_redis_checkpoint_key(thread_id, checkpoint_ns, checkpoint_id)\n",
    "\n",
    "        type_, serialized_checkpoint = self.serde.dumps_typed(checkpoint)\n",
    "        serialized_metadata = self.serde.dumps(metadata)\n",
    "        data = {\n",
    "            \"checkpoint\": serialized_checkpoint,\n",
    "            \"type\": type_,\n",
    "            \"metadata\": serialized_metadata,\n",
    "            \"parent_checkpoint_id\": parent_checkpoint_id\n",
    "            if parent_checkpoint_id\n",
    "            else \"\",\n",
    "        }\n",
    "        self.conn.hset(key, mapping=data)\n",
    "        return {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"checkpoint_ns\": checkpoint_ns,\n",
    "                \"checkpoint_id\": checkpoint_id,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def put_writes(\n",
    "        self,\n",
    "        config: RunnableConfig,\n",
    "        writes: List[Tuple[str, Any]],\n",
    "        task_id: str,\n",
    "    ) -> RunnableConfig:\n",
    "        \"\"\"Store intermediate writes linked to a checkpoint.\n",
    "\n",
    "        Args:\n",
    "            config (RunnableConfig): Configuration of the related checkpoint.\n",
    "            writes (Sequence[Tuple[str, Any]]): List of writes to store, each as (channel, value) pair.\n",
    "            task_id (str): Identifier for the task creating the writes.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        checkpoint_ns = config[\"configurable\"][\"checkpoint_ns\"]\n",
    "        checkpoint_id = config[\"configurable\"][\"checkpoint_id\"]\n",
    "\n",
    "        for idx, data in enumerate(_dump_writes(self.serde, writes)):\n",
    "            key = _make_redis_checkpoint_writes_key(\n",
    "                thread_id, checkpoint_ns, checkpoint_id, task_id, idx\n",
    "            )\n",
    "            self.conn.hset(key, mapping=data)\n",
    "        return config\n",
    "\n",
    "    def get_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        \"\"\"Get a checkpoint tuple from Redis.\n",
    "\n",
    "        This method retrieves a checkpoint tuple from Redis based on the\n",
    "        provided config. If the config contains a \"checkpoint_id\" key, the checkpoint with\n",
    "        the matching thread ID and checkpoint ID is retrieved. Otherwise, the latest checkpoint\n",
    "        for the given thread ID is retrieved.\n",
    "\n",
    "        Args:\n",
    "            config (RunnableConfig): The config to use for retrieving the checkpoint.\n",
    "\n",
    "        Returns:\n",
    "            Optional[CheckpointTuple]: The retrieved checkpoint tuple, or None if no matching checkpoint was found.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        checkpoint_id = get_checkpoint_id(config)\n",
    "        checkpoint_ns = config[\"configurable\"].get(\"checkpoint_ns\", \"\")\n",
    "\n",
    "        checkpoint_key = self._get_checkpoint_key(\n",
    "            self.conn, thread_id, checkpoint_ns, checkpoint_id\n",
    "        )\n",
    "        if not checkpoint_key:\n",
    "            return None\n",
    "\n",
    "        checkpoint_data = self.conn.hgetall(checkpoint_key)\n",
    "\n",
    "        # load pending writes\n",
    "        checkpoint_id = (\n",
    "            checkpoint_id\n",
    "            or _parse_redis_checkpoint_key(checkpoint_key)[\"checkpoint_id\"]\n",
    "        )\n",
    "        writes_key = _make_redis_checkpoint_writes_key(\n",
    "            thread_id, checkpoint_ns, checkpoint_id, \"*\", None\n",
    "        )\n",
    "        matching_keys = self.conn.keys(pattern=writes_key)\n",
    "        parsed_keys = [\n",
    "            _parse_redis_checkpoint_writes_key(key.decode()) for key in matching_keys\n",
    "        ]\n",
    "        pending_writes = _load_writes(\n",
    "            self.serde,\n",
    "            {\n",
    "                (parsed_key[\"task_id\"], parsed_key[\"idx\"]): self.conn.hgetall(key)\n",
    "                for key, parsed_key in sorted(\n",
    "                    zip(matching_keys, parsed_keys), key=lambda x: x[1][\"idx\"]\n",
    "                )\n",
    "            },\n",
    "        )\n",
    "        return _parse_redis_checkpoint_data(\n",
    "            self.serde, checkpoint_key, checkpoint_data, pending_writes=pending_writes\n",
    "        )\n",
    "\n",
    "    def list(\n",
    "        self,\n",
    "        config: Optional[RunnableConfig],\n",
    "        *,\n",
    "        # TODO: implement filtering\n",
    "        filter: Optional[dict[str, Any]] = None,\n",
    "        before: Optional[RunnableConfig] = None,\n",
    "        limit: Optional[int] = None,\n",
    "    ) -> Iterator[CheckpointTuple]:\n",
    "        \"\"\"List checkpoints from the database.\n",
    "\n",
    "        This method retrieves a list of checkpoint tuples from Redis based\n",
    "        on the provided config. The checkpoints are ordered by checkpoint ID in descending order (newest first).\n",
    "\n",
    "        Args:\n",
    "            config (RunnableConfig): The config to use for listing the checkpoints.\n",
    "            filter (Optional[Dict[str, Any]]): Additional filtering criteria for metadata. Defaults to None.\n",
    "            before (Optional[RunnableConfig]): If provided, only checkpoints before the specified checkpoint ID are returned. Defaults to None.\n",
    "            limit (Optional[int]): The maximum number of checkpoints to return. Defaults to None.\n",
    "\n",
    "        Yields:\n",
    "            Iterator[CheckpointTuple]: An iterator of checkpoint tuples.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        checkpoint_ns = config[\"configurable\"].get(\"checkpoint_ns\", \"\")\n",
    "        pattern = _make_redis_checkpoint_key(thread_id, checkpoint_ns, \"*\")\n",
    "\n",
    "        keys = _filter_keys(self.conn.keys(pattern), before, limit)\n",
    "        for key in keys:\n",
    "            data = self.conn.hgetall(key)\n",
    "            if data and b\"checkpoint\" in data and b\"metadata\" in data:\n",
    "                yield _parse_redis_checkpoint_data(self.serde, key.decode(), data)\n",
    "\n",
    "    def _get_checkpoint_key(\n",
    "        self, conn, thread_id: str, checkpoint_ns: str, checkpoint_id: Optional[str]\n",
    "    ) -> Optional[str]:\n",
    "        \"\"\"Determine the Redis key for a checkpoint.\"\"\"\n",
    "        if checkpoint_id:\n",
    "            return _make_redis_checkpoint_key(thread_id, checkpoint_ns, checkpoint_id)\n",
    "\n",
    "        all_keys = conn.keys(_make_redis_checkpoint_key(thread_id, checkpoint_ns, \"*\"))\n",
    "        if not all_keys:\n",
    "            return None\n",
    "\n",
    "        latest_key = max(\n",
    "            all_keys,\n",
    "            key=lambda k: _parse_redis_checkpoint_key(k.decode())[\"checkpoint_id\"],\n",
    "        )\n",
    "        return latest_key.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "\n",
    "\n",
    "tools = [get_weather]\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with RedisSaver.from_conn_info(host=\"localhost\", port=6379, db=0) as checkpointer:\n",
    "    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    res = graph.invoke({\"messages\": [(\"human\", \"what's the weather in sf\")]}, config)\n",
    "\n",
    "    latest_checkpoint = checkpointer.get(config)\n",
    "    latest_checkpoint_tuple = checkpointer.get_tuple(config)\n",
    "    checkpoint_tuples = list(checkpointer.list(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of `magic_function` for the input of 3 is 5.\n",
      "---\n",
      "Yes, you mentioned your name is Polly! How can I assist you today?\n",
      "---\n",
      "The output of `magic_function` for the input of 3 is 5.\n",
      "---\n",
      "The output of `magic_function` for the input of 5 is 7.\n",
      "---\n",
      "Your two names are Polly and Jorge.\n"
     ]
    }
   ],
   "source": [
    "# from langgraph.checkpoint.memory import MemorySaver  # an in-memory checkpointer\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "system_message = \"You are a helpful assistant.\"\n",
    "# This could also be a SystemMessage object\n",
    "# system_message = SystemMessage(content=\"You are a helpful assistant. Respond only in Spanish.\")\n",
    "\n",
    "@tool\n",
    "def magic_function(input: int) -> int:\n",
    "    \"\"\"Applies a magic function to an input.\"\"\"\n",
    "    return input + 2\n",
    "\n",
    "\n",
    "tools = [magic_function]\n",
    "\n",
    "conn = Redis(host='localhost', port=6379, db=0)\n",
    "memory = RedisSaver(conn)\n",
    "langgraph_agent_executor = create_react_agent(\n",
    "    model, tools, state_modifier=system_message, checkpointer=memory\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
    "print(\n",
    "    langgraph_agent_executor.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                (\"user\", \"Hi, I'm polly! What's the output of magic_function of 3?\")\n",
    "            ]\n",
    "        },\n",
    "        config,\n",
    "    )[\"messages\"][-1].content\n",
    ")\n",
    "print(\"---\")\n",
    "print(\n",
    "    langgraph_agent_executor.invoke(\n",
    "        {\"messages\": [(\"user\", \"Remember my name?\")]}, config\n",
    "    )[\"messages\"][-1].content\n",
    ")\n",
    "print(\"---\")\n",
    "print(\n",
    "    langgraph_agent_executor.invoke(\n",
    "        {\"messages\": [(\"user\", \"what was that output again?\")]}, config\n",
    "    )[\"messages\"][-1].content\n",
    ")\n",
    "print(\"---\")\n",
    "print(\n",
    "    langgraph_agent_executor.invoke(\n",
    "        {\"messages\": [(\"user\", \"My new name is Jorge, now, what's the output of the function of 5\")]}, config\n",
    "    )[\"messages\"][-1].content\n",
    ")\n",
    "print(\"---\")\n",
    "print(\n",
    "    langgraph_agent_executor.invoke(\n",
    "        {\"messages\": [(\"user\", \"What are my 2 names?\")]}, config\n",
    "    )[\"messages\"][-1].content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v': 1,\n",
       " 'ts': '2024-10-20T06:19:41.074295+00:00',\n",
       " 'id': '1ef8eab4-a695-6422-8003-2a9cf0a1cb00',\n",
       " 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", additional_kwargs={}, response_metadata={}, id='b872acde-1c55-4ce3-89c9-7496d822dd7f'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Yqwej9vERQAZuMnEXGHCaxY1', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b3bca4c5-3dbf-47bd-8c8b-4250a1920fec-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_Yqwej9vERQAZuMnEXGHCaxY1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "   ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='4119b9f4-4238-420f-a963-b9d4bfac28d8', tool_call_id='call_Yqwej9vERQAZuMnEXGHCaxY1'),\n",
       "   AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'stop', 'logprobs': None}, id='run-1c5895c2-d1ae-4a24-9afc-7b981ee38963-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})],\n",
       "  'agent': 'agent'},\n",
       " 'channel_versions': {'__start__': 2,\n",
       "  'messages': 5,\n",
       "  'start:agent': 3,\n",
       "  'agent': 5,\n",
       "  'branch:agent:should_continue:tools': 4,\n",
       "  'tools': 5},\n",
       " 'versions_seen': {'__input__': {},\n",
       "  '__start__': {'__start__': 1},\n",
       "  'agent': {'start:agent': 2, 'tools': 4},\n",
       "  'tools': {'branch:agent:should_continue:tools': 3}},\n",
       " 'pending_sends': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CheckpointTuple(config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef8eab4-a695-6422-8003-2a9cf0a1cb00'}}, checkpoint={'v': 1, 'ts': '2024-10-20T06:19:41.074295+00:00', 'id': '1ef8eab4-a695-6422-8003-2a9cf0a1cb00', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", additional_kwargs={}, response_metadata={}, id='b872acde-1c55-4ce3-89c9-7496d822dd7f'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Yqwej9vERQAZuMnEXGHCaxY1', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b3bca4c5-3dbf-47bd-8c8b-4250a1920fec-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_Yqwej9vERQAZuMnEXGHCaxY1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='4119b9f4-4238-420f-a963-b9d4bfac28d8', tool_call_id='call_Yqwej9vERQAZuMnEXGHCaxY1'), AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'stop', 'logprobs': None}, id='run-1c5895c2-d1ae-4a24-9afc-7b981ee38963-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'agent': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 5, 'start:agent': 3, 'agent': 5, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'start:agent': 2, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'stop', 'logprobs': None}, id='run-1c5895c2-d1ae-4a24-9afc-7b981ee38963-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}, 'step': 3, 'parents': {}}, parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef8eab4-9ea8-6ad4-8002-79c0737adca9'}}, pending_writes=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_checkpoint_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CheckpointTuple(config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef8eab4-a695-6422-8003-2a9cf0a1cb00'}}, checkpoint={'v': 1, 'ts': '2024-10-20T06:19:41.074295+00:00', 'id': '1ef8eab4-a695-6422-8003-2a9cf0a1cb00', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", additional_kwargs={}, response_metadata={}, id='b872acde-1c55-4ce3-89c9-7496d822dd7f'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Yqwej9vERQAZuMnEXGHCaxY1', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b3bca4c5-3dbf-47bd-8c8b-4250a1920fec-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_Yqwej9vERQAZuMnEXGHCaxY1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='4119b9f4-4238-420f-a963-b9d4bfac28d8', tool_call_id='call_Yqwej9vERQAZuMnEXGHCaxY1'), AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'stop', 'logprobs': None}, id='run-1c5895c2-d1ae-4a24-9afc-7b981ee38963-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'agent': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 5, 'start:agent': 3, 'agent': 5, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'start:agent': 2, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'stop', 'logprobs': None}, id='run-1c5895c2-d1ae-4a24-9afc-7b981ee38963-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}, 'step': 3, 'parents': {}}, parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef8eab4-9ea8-6ad4-8002-79c0737adca9'}}, pending_writes=None),\n",
       " CheckpointTuple(config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef8eab4-9ea8-6ad4-8002-79c0737adca9'}}, checkpoint={'v': 1, 'ts': '2024-10-20T06:19:40.243406+00:00', 'id': '1ef8eab4-9ea8-6ad4-8002-79c0737adca9', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", additional_kwargs={}, response_metadata={}, id='b872acde-1c55-4ce3-89c9-7496d822dd7f'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Yqwej9vERQAZuMnEXGHCaxY1', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b3bca4c5-3dbf-47bd-8c8b-4250a1920fec-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_Yqwej9vERQAZuMnEXGHCaxY1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='4119b9f4-4238-420f-a963-b9d4bfac28d8', tool_call_id='call_Yqwej9vERQAZuMnEXGHCaxY1')], 'tools': 'tools'}, 'channel_versions': {'__start__': 2, 'messages': 4, 'start:agent': 3, 'agent': 4, 'branch:agent:should_continue:tools': 4, 'tools': 4}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'start:agent': 2}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'tools': {'messages': [ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='4119b9f4-4238-420f-a963-b9d4bfac28d8', tool_call_id='call_Yqwej9vERQAZuMnEXGHCaxY1')]}}, 'step': 2, 'parents': {}}, parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef8eab4-9ea3-65ac-8001-fa02a046f62b'}}, pending_writes=None),\n",
       " CheckpointTuple(config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef8eab4-9ea3-65ac-8001-fa02a046f62b'}}, checkpoint={'v': 1, 'ts': '2024-10-20T06:19:40.241218+00:00', 'id': '1ef8eab4-9ea3-65ac-8001-fa02a046f62b', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", additional_kwargs={}, response_metadata={}, id='b872acde-1c55-4ce3-89c9-7496d822dd7f'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Yqwej9vERQAZuMnEXGHCaxY1', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b3bca4c5-3dbf-47bd-8c8b-4250a1920fec-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_Yqwej9vERQAZuMnEXGHCaxY1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'agent': 'agent', 'branch:agent:should_continue:tools': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 3, 'start:agent': 3, 'agent': 3, 'branch:agent:should_continue:tools': 3}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'start:agent': 2}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Yqwej9vERQAZuMnEXGHCaxY1', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b3bca4c5-3dbf-47bd-8c8b-4250a1920fec-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_Yqwej9vERQAZuMnEXGHCaxY1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}, 'step': 1, 'parents': {}}, parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef8eab4-9553-6376-8000-4a6258c94fc2'}}, pending_writes=None),\n",
       " CheckpointTuple(config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef8eab4-9553-6376-8000-4a6258c94fc2'}}, checkpoint={'v': 1, 'ts': '2024-10-20T06:19:39.264693+00:00', 'id': '1ef8eab4-9553-6376-8000-4a6258c94fc2', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", additional_kwargs={}, response_metadata={}, id='b872acde-1c55-4ce3-89c9-7496d822dd7f')], 'start:agent': '__start__'}, 'channel_versions': {'__start__': 2, 'messages': 2, 'start:agent': 2}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': None, 'step': 0, 'parents': {}}, parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef8eab4-954e-6ae2-bfff-7c65fee95fce'}}, pending_writes=None),\n",
       " CheckpointTuple(config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef8eab4-954e-6ae2-bfff-7c65fee95fce'}}, checkpoint={'v': 1, 'ts': '2024-10-20T06:19:39.262841+00:00', 'id': '1ef8eab4-954e-6ae2-bfff-7c65fee95fce', 'channel_values': {'__start__': {'messages': [['human', \"what's the weather in sf\"]]}}, 'channel_versions': {'__start__': 1}, 'versions_seen': {'__input__': {}}, 'pending_sends': []}, metadata={'source': 'input', 'writes': {'__start__': {'messages': [['human', \"what's the weather in sf\"]]}}, 'step': -1, 'parents': {}}, parent_config=None, pending_writes=None)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_tuples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zolkin-backend-dA_7IZFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
